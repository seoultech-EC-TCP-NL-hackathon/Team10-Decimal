# main.py (is_korean_only ë¡œì§ ìˆ˜ì •)
import os
import shutil
import time
from datetime import datetime, timezone
from fastapi import (
    FastAPI,
    Depends,
    HTTPException,
    UploadFile,
    File,
    Form,
    BackgroundTasks,
    Response,
)
from fastapi.responses import JSONResponse
from pathlib import Path
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi.middleware.cors import CORSMiddleware

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
import models
import schemas
from database import SessionLocal, engine

# --- ì„¤ì • (Configurations) ---
models.Base.metadata.create_all(bind=engine)
UPLOAD_DIR = Path("./uploads")
ALLOWED_EXTENSIONS = {".mp3", ".aac", ".m4a", ".wav", ".flac", ".ogg", ".opus", ".webm"}
MAX_FILES = 1
MAX_FILE_SIZE_BYTES = 10 * 1024 * 1024 * 1024  # 10GB

app = FastAPI()

# --- CORS ì„¤ì • ---
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://127.0.0.1:8000",
    "http://127.0.0.1:5500",  # Live Server í¬íŠ¸
    "http://localhost:5500",
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- ì˜ì¡´ì„± (Dependencies) ---
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# --- AI íŒŒíŠ¸ ê°€ìƒ í•¨ìˆ˜ (ì‹œê·¸ë‹ˆì²˜ ë³€ê²½ ì—†ìŒ) ---
def call_ai_model(file_path: Path, source_type: str, is_korean_only: bool) -> dict:
    """AI íŒŒì´í”„ë¼ì¸ì„ í˜¸ì¶œí•˜ëŠ” ê°€ìƒ í•¨ìˆ˜"""
    print(f"INFO: [AI] '{file_path.name}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ (íƒ€ì…: {source_type})")

    if is_korean_only:
        print("INFO: [AI] === í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš© ===")
    else:
        print("INFO: [AI] === ì¼ë°˜ ëª¨ë¸ ì‚¬ìš© ===")

    processing_time = os.path.getsize(file_path) / (1024 * 512)
    time.sleep(processing_time)

    segments = [
        {
            "speaker_label": "Speaker 1",
            "start_time_seconds": 0.5,
            "end_time_seconds": 4.2,
            "text": "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê°•ì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
        },
        {
            "speaker_label": "Speaker 2",
            "start_time_seconds": 5.1,
            "end_time_seconds": 9.8,
            "text": "ë„¤, êµìˆ˜ë‹˜. ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤.",
        },
    ]

    save_dir = file_path.parent
    speaker_text_path = save_dir / "speaker_transcript.txt"
    with open(speaker_text_path, "w", encoding="utf-8") as f:
        f.write("[00:00:00.500] Speaker 1: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê°•ì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n")
        f.write(
            "[00:00:05.100] Speaker 2: ë„¤, êµìˆ˜ë‹˜. ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤.\n"
        )

    print(f"INFO: [AI] '{file_path.name}' íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ.")
    return {
        "transcription_segments": segments,
        "individual_summary": f"'{file_path.name}'ì— ëŒ€í•œ AI ê°œë³„ ìš”ì•½ë³¸ì…ë‹ˆë‹¤.",
        "output_artifacts": {"speaker_attributed_text_path": str(speaker_text_path)},
    }


# --- ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (is_korean_only í”Œë˜ê·¸ ì¡°íšŒ ë¡œì§ ìˆ˜ì •) ---
def run_ai_processing(job_id: int):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë  AI ì²˜ë¦¬ ì „ì²´ ê³¼ì •"""
    print(f"INFO: [ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘] Job ID: {job_id}")
    db = SessionLocal()
    job = None
    transcribe_log = None
    summarize_log = None

    try:
        job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
        if not job:
            print(f"ERROR: Job ID {job_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return

        # ---  1. Subjectì—ì„œ is_korean_only í”Œë˜ê·¸ ê°€ì ¸ì˜¤ê¸°  ---
        is_korean_flag = False  # ê¸°ë³¸ê°’
        if job.subject_id:
            subject = (
                db.query(models.Subject)
                .filter(models.Subject.id == job.subject_id)
                .first()
            )
            if subject:
                is_korean_flag = subject.is_korean_only

        print(
            f"INFO: [AI] ì‘ì—… {job_id}ì˜ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€: {is_korean_flag}"
        )

        job.status = models.JobStatus.PROCESSING
        job.started_at = datetime.now(timezone.utc)
        db.commit()

        transcribe_log = models.JobStageLog(
            job_id=job_id,
            stage_name="transcribe",
            status=models.JobStatus.PROCESSING,
            start_time=datetime.now(timezone.utc),
        )
        db.add(transcribe_log)
        db.commit()

        for material in job.source_materials:
            material.status = models.MaterialStatus.TRANSCRIBING
            db.commit()

            # ---  2. call_ai_modelë¡œ í”Œë˜ê·¸ ê°’ ì „ë‹¬  ---
            ai_results = call_ai_model(
                Path(material.storage_path),
                material.source_type,
                is_korean_flag,  # Subjectì—ì„œ ê°€ì ¸ì˜¨ í”Œë˜ê·¸
            )

            for seg_data in ai_results["transcription_segments"]:
                segment = models.SpeakerAttributedSegment(
                    material_id=material.id, **seg_data
                )
                db.add(segment)

            material.individual_summary = ai_results["individual_summary"]
            material.output_artifacts = ai_results["output_artifacts"]
            material.status = models.MaterialStatus.SUMMARIZING

        db.commit()

        transcribe_log.status = models.JobStatus.COMPLETED
        transcribe_log.end_time = datetime.now(timezone.utc)
        db.commit()

        summarize_log = models.JobStageLog(
            job_id=job_id,
            stage_name="summarize",
            status=models.JobStatus.PROCESSING,
            start_time=datetime.now(timezone.utc),
        )
        db.add(summarize_log)
        db.commit()

        all_summaries = [
            m.individual_summary for m in job.source_materials if m.individual_summary
        ]
        final_summary_content = "\n\n---\n\n".join(all_summaries)

        job.final_summary = f"# {job.title} ìµœì¢… ìš”ì•½\n\n{final_summary_content}"

        for material in job.source_materials:
            material.status = models.MaterialStatus.COMPLETED

        summarize_log.status = models.JobStatus.COMPLETED
        summarize_log.end_time = datetime.now(timezone.utc)

        job.status = models.JobStatus.COMPLETED
        job.completed_at = datetime.now(timezone.utc)
        db.commit()
        print(f"INFO: [ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì„±ê³µ] Job ID: {job_id}")

    except Exception as e:
        # ... (ì˜ˆì™¸ ì²˜ë¦¬ ë™ì¼) ...
        print(f"ERROR: [ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤íŒ¨] Job ID: {job_id}, ì—ëŸ¬: {e}")
        if job:
            job.status = models.JobStatus.FAILED
            job.error_message = f"Processing failed: {type(e).__name__} - {str(e)}"
            if transcribe_log and transcribe_log.status == models.JobStatus.PROCESSING:
                transcribe_log.status = models.JobStatus.FAILED
                transcribe_log.end_time = datetime.now(timezone.utc)
            if summarize_log and summarize_log.status == models.JobStatus.PROCESSING:
                summarize_log.status = models.JobStatus.FAILED
                summarize_log.end_time = datetime.now(timezone.utc)
            db.commit()
    finally:
        db.close()


# --- API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ ---


@app.post("/workspaces", response_model=schemas.Workspace, status_code=201)
def create_workspace(workspace: schemas.WorkspaceCreate, db: Session = Depends(get_db)):
    existing = (
        db.query(models.Workspace)
        .filter(models.Workspace.name == workspace.name)
        .first()
    )
    if existing:
        raise HTTPException(
            status_code=409,
            detail=f"Workspace with name '{workspace.name}' already exists.",
        )

    db_workspace = models.Workspace(**workspace.model_dump())
    db.add(db_workspace)
    db.commit()
    db.refresh(db_workspace)
    return db_workspace


@app.get("/workspaces", response_model=List[schemas.WorkspaceDetail])
def read_workspaces(db: Session = Depends(get_db)):
    return db.query(models.Workspace).all()


# ---  Subject API ìˆ˜ì • (is_korean_only ì €ì¥)  ---
@app.post("/subjects", response_model=schemas.Subject, status_code=201)
def create_subject(subject: schemas.SubjectCreate, db: Session = Depends(get_db)):
    workspace = (
        db.query(models.Workspace)
        .filter(models.Workspace.id == subject.workspace_id)
        .first()
    )
    if not workspace:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid workspace_id: {subject.workspace_id}. Workspace not found.",
        )

    existing_subject = (
        db.query(models.Subject).filter(models.Subject.name == subject.name).first()
    )
    if existing_subject:
        raise HTTPException(
            status_code=409,
            detail=f"Subject with name '{subject.name}' already exists.",
        )

    #  subject.model_dump()ê°€ is_korean_only ê°’ì„ í¬í•¨í•˜ì—¬ ì „ë‹¬
    db_subject = models.Subject(**subject.model_dump())
    db.add(db_subject)
    db.commit()
    db.refresh(db_subject)
    return db_subject


@app.get("/subjects", response_model=List[schemas.SubjectDetail])
def read_subjects(workspace_id: Optional[int] = None, db: Session = Depends(get_db)):
    query = db.query(models.Subject)
    if workspace_id:
        query = query.filter(models.Subject.workspace_id == workspace_id)
    return query.all()


@app.delete("/subjects/{subject_id}", status_code=204)
def delete_subject(subject_id: int, db: Session = Depends(get_db)):
    subject = db.query(models.Subject).filter(models.Subject.id == subject_id).first()
    if not subject:
        raise HTTPException(
            status_code=404, detail=f"Subject with id {subject_id} not found."
        )
    db.delete(subject)
    db.commit()
    return Response(status_code=204)


# ---  Summary Job API ìˆ˜ì • (ë…¹ìŒ íŒŒì¼ ì €ì¥)  ---
@app.post("/summary-jobs", response_model=schemas.SummaryJobDetail, status_code=201)
async def create_summary_job_with_files(
    background_tasks: BackgroundTasks,
    title: str = Form(...),
    subject_id: Optional[int] = Form(None),
    korean_only: bool = Form(False),  # í•œêµ­ì–´ íŠ¹í™” íŒŒë¼ë¯¸í„° í™œì„±í™”
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
):
    # ğŸ” ë°›ì€ ê°’ ë¡œê·¸ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ [í”„ë¡ íŠ¸ì—”ë“œ ìš”ì²­ ìƒì„¸]")
    print(f"{'='*60}")
    print(f"  title: '{title}'")
    print(f"  subject_id: {subject_id}")
    print(f"  korean_only: {korean_only}")
    print(f"  files: {[f.filename for f in files]}")

    # titleì—ì„œ workspaceì™€ subject ë¶„ë¦¬ (title í˜•ì‹: "workspace - subject")
    workspace_name = None
    subject_name = None
    if " - " in title:
        parts = title.split(" - ", 1)
        workspace_name = parts[0]
        subject_name = parts[1]
        print(f"  âœ… Workspace: '{workspace_name}'")
        print(f"  âœ… Subject: '{subject_name}'")
    else:
        print(f"  âš ï¸ titleì´ 'workspace - subject' í˜•ì‹ì´ ì•„ë‹˜")
    print(f"{'='*60}\n")

    # --- ì…ë ¥ ê²€ì¦ ë¡œì§ ---
    if len(files) != MAX_FILES:
        raise HTTPException(
            status_code=400, detail=f"Exactly {MAX_FILES} file must be uploaded."
        )
    file = files[0]
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        allowed_ext_str = ", ".join(ALLOWED_EXTENSIONS)
        raise HTTPException(
            status_code=415,
            detail=f"File format not allowed. Allowed formats: {allowed_ext_str}",
        )

    if file.size is None:
        raise HTTPException(
            status_code=411, detail="File size could not be determined."
        )
    elif file.size > MAX_FILE_SIZE_BYTES:
        raise HTTPException(
            status_code=413, detail=f"File size exceeds the limit of 10GB."
        )

    if subject_id is not None:
        subject = (
            db.query(models.Subject).filter(models.Subject.id == subject_id).first()
        )
        if not subject:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid subject_id: {subject_id}. Subject not found.",
            )
    else:
        # subject_idê°€ ì—†ìœ¼ë©´ titleì—ì„œ íŒŒì‹±í•˜ì—¬ ìë™ ìƒì„±
        if workspace_name and subject_name:
            # Workspace ì°¾ê¸° ë˜ëŠ” ìƒì„±
            workspace = (
                db.query(models.Workspace)
                .filter(models.Workspace.name == workspace_name)
                .first()
            )
            if not workspace:
                workspace = models.Workspace(name=workspace_name)
                db.add(workspace)
                db.commit()
                db.refresh(workspace)
                print(f"âœ… Workspace ìƒì„±ë¨: '{workspace_name}' (ID: {workspace.id})")

            # Subject ì°¾ê¸° ë˜ëŠ” ìƒì„± (is_korean_only ê°’ í¬í•¨)
            subject = (
                db.query(models.Subject)
                .filter(
                    models.Subject.name == subject_name,
                    models.Subject.workspace_id == workspace.id,
                )
                .first()
            )
            if not subject:
                subject = models.Subject(
                    name=subject_name,
                    workspace_id=workspace.id,
                    is_korean_only=korean_only,  # í•œêµ­ì–´ íŠ¹í™” ê°’ ì €ì¥
                )
                db.add(subject)
                db.commit()
                db.refresh(subject)
                print(
                    f"âœ… Subject ìƒì„±ë¨: '{subject_name}' (ID: {subject.id}, Korean Only: {korean_only})"
                )

            subject_id = subject.id

    # --- ê²€ì¦ í†µê³¼ í›„ ë¡œì§ ---
    summary_job = models.SummaryJob(title=title, subject_id=subject_id)
    db.add(summary_job)
    db.commit()
    db.refresh(summary_job)

    # ... (íŒŒì¼ ì €ì¥ ë° SourceMaterial ìƒì„± ë¡œì§ ë™ì¼) ...
    save_dir = UPLOAD_DIR / "source_materials" / str(summary_job.id)
    os.makedirs(save_dir, exist_ok=True)
    file_location = save_dir / file.filename
    try:
        with open(file_location, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=500, detail=f"Failed to save uploaded file: {e}"
        )
    finally:
        await file.close()

    source_material = models.SourceMaterial(
        job_id=summary_job.id,
        source_type=file.content_type or "unknown",
        original_filename=file.filename,
        storage_path=str(file_location),
        file_size_bytes=file.size,
    )
    db.add(source_material)
    db.commit()
    db.refresh(summary_job)

    background_tasks.add_task(run_ai_processing, summary_job.id)
    return summary_job


# --- (ë‚˜ë¨¸ì§€ GET, DELETE APIëŠ” ë³€ê²½ ì—†ìŒ) ---
@app.get("/summary-jobs", response_model=List[schemas.SummaryJobDetail])
def read_summary_jobs(subject_id: Optional[int] = None, db: Session = Depends(get_db)):
    query = db.query(models.SummaryJob).order_by(models.SummaryJob.created_at.desc())
    if subject_id:
        query = query.filter(models.SummaryJob.subject_id == subject_id)
    return query.all()


@app.get("/summary-jobs/{job_id}", response_model=schemas.SummaryJobDetail)
def read_summary_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")
    return job


@app.get("/summary-jobs/{job_id}/download")
def download_summary(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()

    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")
    if job.status != models.JobStatus.COMPLETED:
        raise HTTPException(
            status_code=400,
            detail=f"Job {job_id} is not completed yet (status: {job.status}).",
        )

    if not job.final_summary:
        raise HTTPException(
            status_code=404, detail=f"Summary content for job {job_id} not found."
        )

    return Response(
        content=job.final_summary,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f"attachment; filename=summary_job_{job_id}.md"
        },
    )


@app.delete("/summary-jobs/{job_id}", status_code=200)
def delete_summary_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")

    job_dir = UPLOAD_DIR / "source_materials" / str(job_id)
    if os.path.isdir(job_dir):
        try:
            shutil.rmtree(job_dir)
        except OSError as e:
            print(f"Error deleting directory {job_dir}: {e}")

    db.delete(job)
    db.commit()
    return JSONResponse(
        content={"message": f"Job {job_id} and associated files deleted successfully."}
    )
