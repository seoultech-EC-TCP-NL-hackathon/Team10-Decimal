# main.py (is_korean_only Î°úÏßÅ ÏàòÏ†ï)
import os
import shutil
import time
from datetime import datetime, timezone
from fastapi import (
    FastAPI,
    Depends,
    HTTPException,
    UploadFile,
    File,
    Form,
    BackgroundTasks,
    Response,
)
from fastapi.responses import JSONResponse
from pathlib import Path
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi.middleware.cors import CORSMiddleware

# Î°úÏª¨ Î™®Îìà ÏûÑÌè¨Ìä∏
import models
import schemas
from database import SessionLocal, engine

# --- ÏÑ§Ï†ï (Configurations) ---
models.Base.metadata.create_all(bind=engine)
UPLOAD_DIR = Path("./uploads")
ALLOWED_EXTENSIONS = {".mp3", ".aac", ".m4a", ".wav", ".flac", ".ogg", ".opus", ".webm"}
MAX_FILES = 1
MAX_FILE_SIZE_BYTES = 10 * 1024 * 1024 * 1024  # 10GB

app = FastAPI()

# --- CORS ÏÑ§Ï†ï ---
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://127.0.0.1:8000",
    "http://127.0.0.1:5500",  # Live Server Ìè¨Ìä∏
    "http://localhost:5500",
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- ÏùòÏ°¥ÏÑ± (Dependencies) ---
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# --- AI ÌååÌä∏ Í∞ÄÏÉÅ Ìï®Ïàò (ÏãúÍ∑∏ÎãàÏ≤ò Î≥ÄÍ≤Ω ÏóÜÏùå) ---
def call_ai_model(file_path: Path, source_type: str, is_korean_only: bool) -> dict:
    """AI ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Ìò∏Ï∂úÌïòÎäî Í∞ÄÏÉÅ Ìï®Ïàò"""
    print(f"INFO: [AI] '{file_path.name}' ÌååÏùº Ï≤òÎ¶¨ ÏãúÏûë (ÌÉÄÏûÖ: {source_type})")

    if is_korean_only:
        print("INFO: [AI] === ÌïúÍµ≠Ïñ¥ ÌäπÌôî Î™®Îç∏ ÏÇ¨Ïö© ===")
    else:
        print("INFO: [AI] === ÏùºÎ∞ò Î™®Îç∏ ÏÇ¨Ïö© ===")

    processing_time = os.path.getsize(file_path) / (1024 * 512)
    time.sleep(processing_time)

    segments = [
        {
            "speaker_label": "Speaker 1",
            "start_time_seconds": 0.5,
            "end_time_seconds": 4.2,
            "text": "ÏïàÎÖïÌïòÏÑ∏Ïöî, Ïò§Îäò Í∞ïÏùòÎ•º ÏãúÏûëÌïòÍ≤†ÏäµÎãàÎã§.",
        },
        {
            "speaker_label": "Speaker 2",
            "start_time_seconds": 5.1,
            "end_time_seconds": 9.8,
            "text": "ÎÑ§, ÍµêÏàòÎãò. ÏßÄÎÇú ÏãúÍ∞ÑÏóê Î∞∞Ïö¥ ÎÇ¥Ïö©Ïóê ÎåÄÌï¥ ÏßàÎ¨∏Ïù¥ ÏûàÏäµÎãàÎã§.",
        },
    ]

    save_dir = file_path.parent
    speaker_text_path = save_dir / "speaker_transcript.txt"
    with open(speaker_text_path, "w", encoding="utf-8") as f:
        f.write("[00:00:00.500] Speaker 1: ÏïàÎÖïÌïòÏÑ∏Ïöî, Ïò§Îäò Í∞ïÏùòÎ•º ÏãúÏûëÌïòÍ≤†ÏäµÎãàÎã§.\n")
        f.write(
            "[00:00:05.100] Speaker 2: ÎÑ§, ÍµêÏàòÎãò. ÏßÄÎÇú ÏãúÍ∞ÑÏóê Î∞∞Ïö¥ ÎÇ¥Ïö©Ïóê ÎåÄÌï¥ ÏßàÎ¨∏Ïù¥ ÏûàÏäµÎãàÎã§.\n"
        )

    print(f"INFO: [AI] '{file_path.name}' ÌååÏùº Ï≤òÎ¶¨ ÏôÑÎ£å.")
    return {
        "transcription_segments": segments,
        "individual_summary": f"'{file_path.name}'Ïóê ÎåÄÌïú AI Í∞úÎ≥Ñ ÏöîÏïΩÎ≥∏ÏûÖÎãàÎã§.",
        "output_artifacts": {"speaker_attributed_text_path": str(speaker_text_path)},
    }


# --- Î∞±Í∑∏ÎùºÏö¥Îìú ÏûëÏóÖ (is_korean_only ÌîåÎûòÍ∑∏ Ï°∞Ìöå Î°úÏßÅ ÏàòÏ†ï) ---
def run_ai_processing(job_id: int):
    """Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú Ïã§ÌñâÎê† AI Ï≤òÎ¶¨ Ï†ÑÏ≤¥ Í≥ºÏ†ï"""
    print(f"INFO: [Î∞±Í∑∏ÎùºÏö¥Îìú ÏûëÏóÖ ÏãúÏûë] Job ID: {job_id}")
    db = SessionLocal()
    job = None
    transcribe_log = None
    summarize_log = None

    try:
        job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
        if not job:
            print(f"ERROR: Job ID {job_id}Î•º Ï∞æÏùÑ Ïàò ÏóÜÏùå")
            return

        # ---  1. SubjectÏóêÏÑú is_korean_only ÌîåÎûòÍ∑∏ Í∞ÄÏ†∏Ïò§Í∏∞  ---
        is_korean_flag = False  # Í∏∞Î≥∏Í∞í
        if job.subject_id:
            subject = (
                db.query(models.Subject)
                .filter(models.Subject.id == job.subject_id)
                .first()
            )
            if subject:
                is_korean_flag = subject.is_korean_only

        print(
            f"INFO: [AI] ÏûëÏóÖ {job_id}Ïùò ÌïúÍµ≠Ïñ¥ ÌäπÌôî Î™®Îç∏ ÏÇ¨Ïö© Ïó¨Î∂Ä: {is_korean_flag}"
        )

        job.status = models.JobStatus.PROCESSING
        job.started_at = datetime.now(timezone.utc)
        db.commit()

        transcribe_log = models.JobStageLog(
            job_id=job_id,
            stage_name="transcribe",
            status=models.JobStatus.PROCESSING,
            start_time=datetime.now(timezone.utc),
        )
        db.add(transcribe_log)
        db.commit()

        for material in job.source_materials:
            material.status = models.MaterialStatus.TRANSCRIBING
            db.commit()

            # ---  2. call_ai_modelÎ°ú ÌîåÎûòÍ∑∏ Í∞í Ï†ÑÎã¨  ---
            ai_results = call_ai_model(
                Path(material.storage_path),
                material.source_type,
                is_korean_flag,  # SubjectÏóêÏÑú Í∞ÄÏ†∏Ïò® ÌîåÎûòÍ∑∏
            )

            for seg_data in ai_results["transcription_segments"]:
                segment = models.SpeakerAttributedSegment(
                    material_id=material.id, **seg_data
                )
                db.add(segment)

            material.individual_summary = ai_results["individual_summary"]
            material.output_artifacts = ai_results["output_artifacts"]
            material.status = models.MaterialStatus.SUMMARIZING

        db.commit()

        transcribe_log.status = models.JobStatus.COMPLETED
        transcribe_log.end_time = datetime.now(timezone.utc)
        db.commit()

        summarize_log = models.JobStageLog(
            job_id=job_id,
            stage_name="summarize",
            status=models.JobStatus.PROCESSING,
            start_time=datetime.now(timezone.utc),
        )
        db.add(summarize_log)
        db.commit()

        all_summaries = [
            m.individual_summary for m in job.source_materials if m.individual_summary
        ]
        final_summary_content = "\n\n---\n\n".join(all_summaries)

        job.final_summary = f"# {job.title} ÏµúÏ¢Ö ÏöîÏïΩ\n\n{final_summary_content}"

        for material in job.source_materials:
            material.status = models.MaterialStatus.COMPLETED

        summarize_log.status = models.JobStatus.COMPLETED
        summarize_log.end_time = datetime.now(timezone.utc)

        job.status = models.JobStatus.COMPLETED
        job.completed_at = datetime.now(timezone.utc)
        db.commit()
        print(f"INFO: [Î∞±Í∑∏ÎùºÏö¥Îìú ÏûëÏóÖ ÏÑ±Í≥µ] Job ID: {job_id}")

    except Exception as e:
        # ... (ÏòàÏô∏ Ï≤òÎ¶¨ ÎèôÏùº) ...
        print(f"ERROR: [Î∞±Í∑∏ÎùºÏö¥Îìú ÏûëÏóÖ Ïã§Ìå®] Job ID: {job_id}, ÏóêÎü¨: {e}")
        if job:
            job.status = models.JobStatus.FAILED
            job.error_message = f"Processing failed: {type(e).__name__} - {str(e)}"
            if transcribe_log and transcribe_log.status == models.JobStatus.PROCESSING:
                transcribe_log.status = models.JobStatus.FAILED
                transcribe_log.end_time = datetime.now(timezone.utc)
            if summarize_log and summarize_log.status == models.JobStatus.PROCESSING:
                summarize_log.status = models.JobStatus.FAILED
                summarize_log.end_time = datetime.now(timezone.utc)
            db.commit()
    finally:
        db.close()


# --- API ÏóîÎìúÌè¨Ïù∏Ìä∏ Íµ¨ÌòÑ ---


@app.post("/workspaces", response_model=schemas.Workspace, status_code=201)
def create_workspace(workspace: schemas.WorkspaceCreate, db: Session = Depends(get_db)):
    existing = (
        db.query(models.Workspace)
        .filter(models.Workspace.name == workspace.name)
        .first()
    )
    if existing:
        raise HTTPException(
            status_code=409,
            detail=f"Workspace with name '{workspace.name}' already exists.",
        )

    db_workspace = models.Workspace(**workspace.model_dump())
    db.add(db_workspace)
    db.commit()
    db.refresh(db_workspace)
    return db_workspace


@app.get("/workspaces", response_model=List[schemas.WorkspaceDetail])
def read_workspaces(db: Session = Depends(get_db)):
    return db.query(models.Workspace).all()


# ---  Subject API ÏàòÏ†ï (is_korean_only Ï†ÄÏû•)  ---
@app.post("/subjects", response_model=schemas.Subject, status_code=201)
def create_subject(subject: schemas.SubjectCreate, db: Session = Depends(get_db)):
    workspace = (
        db.query(models.Workspace)
        .filter(models.Workspace.id == subject.workspace_id)
        .first()
    )
    if not workspace:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid workspace_id: {subject.workspace_id}. Workspace not found.",
        )

    existing_subject = (
        db.query(models.Subject).filter(models.Subject.name == subject.name).first()
    )
    if existing_subject:
        raise HTTPException(
            status_code=409,
            detail=f"Subject with name '{subject.name}' already exists.",
        )

    #  subject.model_dump()Í∞Ä is_korean_only Í∞íÏùÑ Ìè¨Ìï®ÌïòÏó¨ Ï†ÑÎã¨
    db_subject = models.Subject(**subject.model_dump())
    db.add(db_subject)
    db.commit()
    db.refresh(db_subject)
    return db_subject


@app.get("/subjects", response_model=List[schemas.SubjectDetail])
def read_subjects(workspace_id: Optional[int] = None, db: Session = Depends(get_db)):
    query = db.query(models.Subject)
    if workspace_id:
        query = query.filter(models.Subject.workspace_id == workspace_id)
    return query.all()


@app.delete("/subjects/{subject_id}", status_code=204)
def delete_subject(subject_id: int, db: Session = Depends(get_db)):
    subject = db.query(models.Subject).filter(models.Subject.id == subject_id).first()
    if not subject:
        raise HTTPException(
            status_code=404, detail=f"Subject with id {subject_id} not found."
        )
    db.delete(subject)
    db.commit()
    return Response(status_code=204)


# ---  Summary Job API ÏàòÏ†ï (ÎÖπÏùå ÌååÏùº Ï†ÄÏû•)  ---
@app.post("/summary-jobs", response_model=schemas.SummaryJobDetail, status_code=201)
async def create_summary_job_with_files(
    background_tasks: BackgroundTasks,
    title: str = Form(...),
    subject_id: Optional[int] = Form(None),
    #  is_korean_only ÌååÎùºÎØ∏ÌÑ∞ Ïó¨Í∏∞ÏÑú ÏÇ≠Ï†ú
    # is_korean_only: bool = Form(False),
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
):
    # üîç Î∞õÏùÄ Í∞í Î°úÍ∑∏ Ï∂úÎ†•
    print(f"\n{'='*60}")
    print(f"üì• [ÌîÑÎ°†Ìä∏ÏóîÎìú ÏöîÏ≤≠ ÏÉÅÏÑ∏]")
    print(f"{'='*60}")
    print(f"  title: '{title}'")
    print(f"  subject_id: {subject_id}")
    print(f"  files: {[f.filename for f in files]}")
    
    # titleÏóêÏÑú workspaceÏôÄ subject Î∂ÑÎ¶¨ (title ÌòïÏãù: "workspace - subject")
    if ' - ' in title:
        parts = title.split(' - ', 1)
        workspace_name = parts[0]
        subject_name = parts[1]
        print(f"  ‚úÖ Workspace: '{workspace_name}'")
        print(f"  ‚úÖ Subject: '{subject_name}'")
    else:
        print(f"  ‚ö†Ô∏è titleÏù¥ 'workspace - subject' ÌòïÏãùÏù¥ ÏïÑÎãò")
    print(f"{'='*60}\n")
    
    # --- ÏûÖÎ†• Í≤ÄÏ¶ù Î°úÏßÅ ---
    if len(files) != MAX_FILES:
        raise HTTPException(
            status_code=400, detail=f"Exactly {MAX_FILES} file must be uploaded."
        )
    file = files[0]
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        allowed_ext_str = ", ".join(ALLOWED_EXTENSIONS)
        raise HTTPException(
            status_code=415,
            detail=f"File format not allowed. Allowed formats: {allowed_ext_str}",
        )

    if file.size is None:
        raise HTTPException(
            status_code=411, detail="File size could not be determined."
        )
    elif file.size > MAX_FILE_SIZE_BYTES:
        raise HTTPException(
            status_code=413, detail=f"File size exceeds the limit of 10GB."
        )

    if subject_id is not None:
        subject = (
            db.query(models.Subject).filter(models.Subject.id == subject_id).first()
        )
        if not subject:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid subject_id: {subject_id}. Subject not found.",
            )

    # --- Í≤ÄÏ¶ù ÌÜµÍ≥º ÌõÑ Î°úÏßÅ ---
    #  is_korean_only Í∞í ÏóÜÏù¥ SummaryJob ÏÉùÏÑ±
    summary_job = models.SummaryJob(title=title, subject_id=subject_id)
    db.add(summary_job)
    db.commit()
    db.refresh(summary_job)

    # ... (ÌååÏùº Ï†ÄÏû• Î∞è SourceMaterial ÏÉùÏÑ± Î°úÏßÅ ÎèôÏùº) ...
    save_dir = UPLOAD_DIR / "source_materials" / str(summary_job.id)
    os.makedirs(save_dir, exist_ok=True)
    file_location = save_dir / file.filename
    try:
        with open(file_location, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=500, detail=f"Failed to save uploaded file: {e}"
        )
    finally:
        await file.close()

    source_material = models.SourceMaterial(
        job_id=summary_job.id,
        source_type=file.content_type or "unknown",
        original_filename=file.filename,
        storage_path=str(file_location),
        file_size_bytes=file.size,
    )
    db.add(source_material)
    db.commit()
    db.refresh(summary_job)

    background_tasks.add_task(run_ai_processing, summary_job.id)
    return summary_job


# --- (ÎÇòÎ®∏ÏßÄ GET, DELETE APIÎäî Î≥ÄÍ≤Ω ÏóÜÏùå) ---
@app.get("/summary-jobs", response_model=List[schemas.SummaryJobDetail])
def read_summary_jobs(subject_id: Optional[int] = None, db: Session = Depends(get_db)):
    query = db.query(models.SummaryJob).order_by(models.SummaryJob.created_at.desc())
    if subject_id:
        query = query.filter(models.SummaryJob.subject_id == subject_id)
    return query.all()


@app.get("/summary-jobs/{job_id}", response_model=schemas.SummaryJobDetail)
def read_summary_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")
    return job


@app.get("/summary-jobs/{job_id}/download")
def download_summary(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()

    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")
    if job.status != models.JobStatus.COMPLETED:
        raise HTTPException(
            status_code=400,
            detail=f"Job {job_id} is not completed yet (status: {job.status}).",
        )

    if not job.final_summary:
        raise HTTPException(
            status_code=404, detail=f"Summary content for job {job_id} not found."
        )

    return Response(
        content=job.final_summary,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f"attachment; filename=summary_job_{job_id}.md"
        },
    )


@app.delete("/summary-jobs/{job_id}", status_code=200)
def delete_summary_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.SummaryJob).filter(models.SummaryJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail=f"Job with id {job_id} not found.")

    job_dir = UPLOAD_DIR / "source_materials" / str(job_id)
    if os.path.isdir(job_dir):
        try:
            shutil.rmtree(job_dir)
        except OSError as e:
            print(f"Error deleting directory {job_dir}: {e}")

    db.delete(job)
    db.commit()
    return JSONResponse(
        content={"message": f"Job {job_id} and associated files deleted successfully."}
    )
